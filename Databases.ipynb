{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLAlchemy database connector\n",
    "\n",
    "SQLAlchemy supports\n",
    "\n",
    "|Dialect|Required Packages|\n",
    "|-----|---|\n",
    "|[Firebird](https://docs.sqlalchemy.org/en/latest/dialects/firebird.html)| `fdb` |\n",
    "|[Microsoft SQL Server](https://docs.sqlalchemy.org/en/latest/dialects/mssql.html)| `pyodbc`, `pymssql` |\n",
    "|[MySQL](https://docs.sqlalchemy.org/en/latest/dialects/mysql.html)| `mysqlclient` |\n",
    "|[PostgreSQL](https://docs.sqlalchemy.org/en/latest/dialects/postgresql.html) | `psycopg2` |\n",
    "|[SQLite](https://docs.sqlalchemy.org/en/latest/dialects/sqlite.html)| `sqlite` |\n",
    "|[Sybase](https://docs.sqlalchemy.org/en/latest/dialects/sybase.html)| `python-sybase` |\n",
    "|[IBM DB2 and Informix](https://github.com/ibmdb/python-ibmdb) | `ibm_db_sa` |\n",
    "|[Oracle](https://docs.sqlalchemy.org/en/latest/dialects/oracle.html)| `cx_oracle`, `oracle-instantclient` |\n",
    "|[HIVE and Presto](https://github.com/dropbox/PyHive) | `pyhive` |\n",
    "|[Impala](https://github.com/cloudera/impyla) | `impyla`|\n",
    "|[Snowflake](https://docs.snowflake.net/manuals/user-guide/sqlalchemy.html) | `snowflake-sqlalchemy`, `snowflake-connector-python` |\n",
    "\n",
    "In order to connect to other database flavors, the protocol will need to be changed along with details of your connection including hostname, username, password, and others.\n",
    "\n",
    "\n",
    "For example, connecting to an Oracle database may require the following information\n",
    "\n",
    "```python\n",
    "username = 'me'\n",
    "password = 'secret'\n",
    "db_host = 'db.example.com'\n",
    "port = 1530\n",
    "service_id = 'my_sid'\n",
    "\n",
    "engine = create_engine(f'oracle://{username}:{password}@{db_host}:{port}/{service_id}')\n",
    "```\n",
    "\n",
    "For this notebook a SQLite database is provided. The same SQLAlchemy function calls will work on any database flavor. **Note** that not all databases support the same SQL operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engines and connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "db = create_engine('sqlite:///db.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the engine you can inspect the database. Most commonly this is used to determine the table names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example a temporary table called `high_mpg` is created and selected from. Once the context manager finishes the temporary table will no longer be available.\n",
    "\n",
    "The connection context manager lets you setup multiple execution *transactions*. On exit those transactions are *committed* and executed on the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with db.connect() as connection:\n",
    "    connection.execute('create temp table high_mpg as select * from autompg where mpg > 30')\n",
    "    result = connection.execute(\"select * from high_mpg where origin = 'America'\")  \n",
    "    data = result.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data returned by `.fetchall()` is a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    print(f'19{row[-3]} {row[-1]:40s}: {row[1]:4.1f} mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since databases contain tabular data reading directly in a Pandas DataFrame can be very convenient. Queries can be performed directly in `.read_sql()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_sql('select * from autompg where yr > 75', db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting with Pandas DataFrames is easy with [HvPlot](https://hvplot.pyviz.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas\n",
    "\n",
    "plot = df.hvplot.scatter(x='hp', y='mpg', c='origin',\n",
    "                         hover_cols=['name','yr'], legend='top_right',\n",
    "                         width=900, padding=0.02)\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `connection` can also be used to mix SQL statement execution and `.read_sql()`. Again we're making a temporary table and using that to select and read into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with db.connect() as connection:\n",
    "    connection.execute('create temp table low_mpg as select * from autompg where mpg < 20')\n",
    "    low_mpg = pd.read_sql(\"select * from low_mpg where origin = 'Asia'\", connection)  \n",
    "\n",
    "low_mpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dask](https://dask.org) let's us process large amounts of data in parallel and *out-of-core*. That means that we don't need a large-memory resource profile, but having more cores will speed up the computation.\n",
    "\n",
    "Here data is not read into memory when `read_sql_table()` is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "db_uri = 'sqlite:///db.sqlite'\n",
    "\n",
    "weather = dd.read_sql_table('weather', db_uri, index_col='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `Date` does not appear in the column list. It is now on the index, which allows for some very powerful operations, especially for datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the total monthly snowfall and monthly average temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowfall = weather['Snowfall'].resample('M').sum()\n",
    "avg_prec = weather['Precipitation Water Equiv'].resample('M').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform the out-of-core computation we must use `.compute()`. This returns and *in-memory* Pandas object.\n",
    "\n",
    "**Caution**: Don't compute the *entire* data set if the return number of rows is very large. Dask is useful because the data does not fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = snowfall.compute()\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here hvplot will perform `.compute()` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.dask\n",
    "\n",
    "snow_plot = snowfall.hvplot.line(y='Snowfall', title='Total Monthly Snowfall')\n",
    "prec_plot = avg_prec.hvplot.line(y='Precipitation Water Equiv', title='Average precipitation')\n",
    "\n",
    "plot = (snow_plot + prec_plot).cols(1)\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<font color='grey'><i>Copyright Anaconda 2012-2019 All Rights Reserved.</i></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
